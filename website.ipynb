{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-locatelli/projet-detection-avions-paul-omar/blob/main/website.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "gu46DUAdZGKB",
        "outputId": "335dbd7b-67ca-4048-fceb-1c51ea1ef1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://eb47f515ecc9f4bac8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eb47f515ecc9f4bac8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# =========================\n",
        "# 0) Install deps\n",
        "# =========================\n",
        "!pip -q install gradio pillow numpy torch torchvision\n",
        "\n",
        "# =========================\n",
        "# 1) Imports + Drive mount\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.ops import nms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "import gradio as gr\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# =========================\n",
        "# 2) Paths on Google Drive\n",
        "# =========================\n",
        "BASE_DIR = \"/content/drive/MyDrive/Final_product\"  # <- folder in your screenshot\n",
        "\n",
        "CLASSIFIER_PATH = os.path.join(BASE_DIR, \"best_crop_classifier_resnet50.pth\")\n",
        "DETECTOR_PATH   = os.path.join(BASE_DIR, \"best_faster_rcnn_raw.pth\")\n",
        "\n",
        "if not os.path.exists(CLASSIFIER_PATH):\n",
        "    raise FileNotFoundError(f\"Missing classifier at: {CLASSIFIER_PATH}\")\n",
        "if not os.path.exists(DETECTOR_PATH):\n",
        "    raise FileNotFoundError(f\"Missing detector at: {DETECTOR_PATH}\")\n",
        "\n",
        "# =========================\n",
        "# 3) Device\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# =========================\n",
        "# 4) Helper: checkpoint parsing\n",
        "# =========================\n",
        "def extract_state_dict(ckpt):\n",
        "    if isinstance(ckpt, dict):\n",
        "        for k in [\"model_state_dict\", \"state_dict\", \"model\", \"weights\"]:\n",
        "            if k in ckpt and isinstance(ckpt[k], dict):\n",
        "                return ckpt[k]\n",
        "        dict_candidates = [v for v in ckpt.values() if isinstance(v, dict)]\n",
        "        if dict_candidates:\n",
        "            return max(dict_candidates, key=lambda d: len(d))\n",
        "        return ckpt\n",
        "    raise ValueError(\"Checkpoint format not supported.\")\n",
        "\n",
        "def strip_module(sd):\n",
        "    if any(k.startswith(\"module.\") for k in sd.keys()):\n",
        "        return {k.replace(\"module.\", \"\", 1): v for k, v in sd.items()}\n",
        "    return sd\n",
        "\n",
        "def infer_detector_num_classes(sd):\n",
        "    k = \"roi_heads.box_predictor.cls_score.weight\"\n",
        "    if k in sd and hasattr(sd[k], \"shape\"):\n",
        "        return int(sd[k].shape[0])\n",
        "    return None\n",
        "\n",
        "# =========================\n",
        "# 5) Load classifier (ResNet50)\n",
        "#   Expected: ckpt contains 'class_to_idx' and 'model_state_dict'\n",
        "# =========================\n",
        "clf_ckpt = torch.load(CLASSIFIER_PATH, map_location=DEVICE)\n",
        "if not isinstance(clf_ckpt, dict) or \"class_to_idx\" not in clf_ckpt:\n",
        "    raise KeyError(\"Classifier checkpoint must contain 'class_to_idx'.\")\n",
        "\n",
        "class_to_idx = clf_ckpt[\"class_to_idx\"]\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "num_classes = len(idx_to_class)\n",
        "\n",
        "clf = torchvision.models.resnet50(weights=None)\n",
        "clf.fc = nn.Linear(clf.fc.in_features, num_classes)\n",
        "\n",
        "clf_sd = clf_ckpt.get(\"model_state_dict\", None)\n",
        "if clf_sd is None:\n",
        "    clf_sd = extract_state_dict(clf_ckpt)\n",
        "clf.load_state_dict(clf_sd, strict=False)\n",
        "\n",
        "clf.to(DEVICE).eval()\n",
        "\n",
        "tf_clf = T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
        "\n",
        "@torch.no_grad()\n",
        "def classify_crop(crop_pil):\n",
        "    x = tf_clf(crop_pil.convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n",
        "    logits = clf(x)[0]\n",
        "    probs = torch.softmax(logits, dim=0).detach().cpu().numpy()\n",
        "    i = int(np.argmax(probs))\n",
        "    return idx_to_class[i], float(probs[i])\n",
        "\n",
        "# =========================\n",
        "# 6) Load detector (Faster R-CNN ResNet50 FPN)\n",
        "# =========================\n",
        "det_ckpt = torch.load(DETECTOR_PATH, map_location=DEVICE)\n",
        "det_sd = strip_module(extract_state_dict(det_ckpt))\n",
        "\n",
        "num_det_classes = infer_detector_num_classes(det_sd)\n",
        "if num_det_classes is None:\n",
        "    raise ValueError(\n",
        "        \"Detector checkpoint not recognized as torchvision Faster R-CNN state_dict.\\n\"\n",
        "        \"If your detector is not FasterRCNN, tell me what model you trained.\"\n",
        "    )\n",
        "\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None, weights_backbone=None)\n",
        "in_features = detector.roi_heads.box_predictor.cls_score.in_features\n",
        "detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_det_classes)\n",
        "\n",
        "detector.load_state_dict(det_sd, strict=False)\n",
        "detector.to(DEVICE).eval()\n",
        "\n",
        "to_tensor = T.ToTensor()\n",
        "\n",
        "@torch.no_grad()\n",
        "def detect(img_pil, det_conf=0.30, iou_nms=0.50, max_boxes=50):\n",
        "    x = to_tensor(img_pil).to(DEVICE)\n",
        "    pred = detector([x])[0]\n",
        "    boxes = pred[\"boxes\"].detach().cpu()\n",
        "    scores = pred[\"scores\"].detach().cpu()\n",
        "\n",
        "    keep = scores >= float(det_conf)\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    if len(boxes) == 0:\n",
        "        return np.zeros((0, 4), dtype=np.float32), np.zeros((0,), dtype=np.float32)\n",
        "\n",
        "    keep_idx = nms(boxes, scores, float(iou_nms))[: int(max_boxes)]\n",
        "    return boxes[keep_idx].numpy().astype(np.float32), scores[keep_idx].numpy().astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 7) Drawing utils\n",
        "# =========================\n",
        "ORANGE = (255, 130, 0)\n",
        "\n",
        "def get_font():\n",
        "    try:\n",
        "        return ImageFont.truetype(\"DejaVuSans.ttf\", 18)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def draw_tag(draw, font, x1, y1, text):\n",
        "    pad_x, pad_y = 8, 4\n",
        "    if font:\n",
        "        bb = draw.textbbox((0, 0), text, font=font)\n",
        "        tw, th = bb[2] - bb[0], bb[3] - bb[1]\n",
        "    else:\n",
        "        tw, th = max(10, 9 * len(text)), 18\n",
        "    y_top = max(0, y1 - (th + 2 * pad_y))\n",
        "    draw.rectangle([x1, y_top, x1 + tw + 2 * pad_x, y1], fill=ORANGE)\n",
        "    draw.text((x1 + pad_x, y_top + pad_y), text, fill=(255, 255, 255), font=font)\n",
        "\n",
        "# =========================\n",
        "# 8) Main pipeline: upload image -> output image with bbox + labels\n",
        "# =========================\n",
        "def run_pipeline(img, det_conf, iou_nms, max_boxes):\n",
        "    if img is None:\n",
        "        return None, \"Upload an image.\"\n",
        "\n",
        "    img = img.convert(\"RGB\")\n",
        "    W, H = img.size\n",
        "    font = get_font()\n",
        "\n",
        "    out = img.copy()\n",
        "    d = ImageDraw.Draw(out)\n",
        "\n",
        "    boxes, dscores = detect(img, det_conf=det_conf, iou_nms=iou_nms, max_boxes=max_boxes)\n",
        "    if len(boxes) == 0:\n",
        "        return out, \"No detections. Try lowering detector confidence.\"\n",
        "\n",
        "    lines = []\n",
        "    shown = 0\n",
        "\n",
        "    for (x1, y1, x2, y2), ds in zip(boxes, dscores):\n",
        "        x1 = int(max(0, min(W - 1, x1)))\n",
        "        y1 = int(max(0, min(H - 1, y1)))\n",
        "        x2 = int(max(0, min(W - 1, x2)))\n",
        "        y2 = int(max(0, min(H - 1, y2)))\n",
        "        if x2 - x1 < 2 or y2 - y1 < 2:\n",
        "            continue\n",
        "\n",
        "        crop = img.crop((x1, y1, x2, y2))\n",
        "        cls, cls_p = classify_crop(crop)\n",
        "\n",
        "        d.rectangle([x1, y1, x2, y2], outline=ORANGE, width=4)\n",
        "        tag = f\"{cls} {cls_p:.2f} | det {float(ds):.2f}\"\n",
        "        draw_tag(d, font, x1, y1, tag)\n",
        "\n",
        "        shown += 1\n",
        "        lines.append(f\"Box {shown}: {tag}  (x1={x1}, y1={y1}, x2={x2}, y2={y2})\")\n",
        "\n",
        "    return out, \"\\n\".join(lines) if lines else \"Detections existed but none were drawable.\"\n",
        "\n",
        "# =========================\n",
        "# 9) Website (Gradio public URL)\n",
        "# =========================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Final Product â€” Detector + BBox + Classifier (Public Website)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        inp = gr.Image(type=\"pil\", label=\"Upload image\")\n",
        "        out = gr.Image(type=\"pil\", label=\"Result (BBox + labels)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        det_conf = gr.Slider(0.01, 0.99, value=0.30, step=0.01, label=\"Detector confidence\")\n",
        "        iou_nms  = gr.Slider(0.10, 0.95, value=0.50, step=0.05, label=\"NMS IoU\")\n",
        "        max_boxes = gr.Slider(1, 200, value=50, step=1, label=\"Max boxes\")\n",
        "\n",
        "    status = gr.Textbox(label=\"Details\", lines=10)\n",
        "    btn = gr.Button(\"Run\", variant=\"primary\")\n",
        "    btn.click(run_pipeline, inputs=[inp, det_conf, iou_nms, max_boxes], outputs=[out, status])\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}