{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-locatelli/projet-detection-avions-paul-omar/blob/main/Model_classificateur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mP_pfb9rPuA",
        "outputId": "a186f1e0-98c0-41c1-da33-1f70a1bef23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Matched pairs: 1331\n",
            "Num classes: 20\n",
            "Classes: ['A1', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A2', 'A20', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9']\n",
            "Split sizes: 1064 133 134\n",
            "Crops counts: 6220 876 774 | total: 7870\n",
            "Meta saved: /content/drive/MyDrive/Final_product/DataSet/dataset_meta.txt\n",
            "‚úÖ Crops copied to Drive: /content/drive/MyDrive/Final_product/DataSet/cls_crops\n",
            "‚úÖ Keys: /content/drive/MyDrive/Final_product/DataSet/splits_keys\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os, glob, pathlib, random, shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/Final_product\"\n",
        "DATASET_ROOT = os.path.join(ROOT, \"DataSet\")\n",
        "RAW_DIR = os.path.join(DATASET_ROOT, \"raw\")\n",
        "OUT_KEYS = os.path.join(DATASET_ROOT, \"splits_keys\")\n",
        "META_PATH = os.path.join(DATASET_ROOT, \"dataset_meta.txt\")\n",
        "\n",
        "# Write crops locally first (FAST), then copy to Drive\n",
        "LOCAL_CROPS = \"/content/cls_crops\"\n",
        "DRIVE_CROPS = os.path.join(DATASET_ROOT, \"cls_crops\")\n",
        "\n",
        "# Clean local output\n",
        "if os.path.exists(LOCAL_CROPS):\n",
        "    shutil.rmtree(LOCAL_CROPS)\n",
        "os.makedirs(LOCAL_CROPS, exist_ok=True)\n",
        "os.makedirs(OUT_KEYS, exist_ok=True)\n",
        "\n",
        "def norm_stem(p):\n",
        "    s = pathlib.Path(p).stem.lower()\n",
        "    s = s.replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\")\n",
        "    return s\n",
        "\n",
        "img_files = sorted(\n",
        "    glob.glob(os.path.join(RAW_DIR, \"**\", \"*.jpg\"), recursive=True) +\n",
        "    glob.glob(os.path.join(RAW_DIR, \"**\", \"*.jpeg\"), recursive=True) +\n",
        "    glob.glob(os.path.join(RAW_DIR, \"**\", \"*.png\"), recursive=True)\n",
        ")\n",
        "xml_files = sorted(glob.glob(os.path.join(RAW_DIR, \"**\", \"*.xml\"), recursive=True))\n",
        "\n",
        "assert len(img_files) > 0, \"No images in raw/\"\n",
        "assert len(xml_files) > 0, \"No xml in raw/\"\n",
        "\n",
        "img_map = {}\n",
        "for p in img_files:\n",
        "    k = norm_stem(p)\n",
        "    if k not in img_map:\n",
        "        img_map[k] = p\n",
        "\n",
        "xml_map = {}\n",
        "for p in xml_files:\n",
        "    k = norm_stem(p)\n",
        "    if k not in xml_map:\n",
        "        xml_map[k] = p\n",
        "\n",
        "matched = sorted(set(img_map.keys()) & set(xml_map.keys()))\n",
        "assert len(matched) > 0, \"No matched image/xml pairs.\"\n",
        "\n",
        "print(\"Matched pairs:\", len(matched))\n",
        "\n",
        "def parse_voc(xml_path):\n",
        "    root = ET.parse(xml_path).getroot()\n",
        "    objs = []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = obj.findtext(\"name\")\n",
        "        bnd = obj.find(\"bndbox\")\n",
        "        if bnd is None:\n",
        "            continue\n",
        "        x1 = int(float(bnd.findtext(\"xmin\")))\n",
        "        y1 = int(float(bnd.findtext(\"ymin\")))\n",
        "        x2 = int(float(bnd.findtext(\"xmax\")))\n",
        "        y2 = int(float(bnd.findtext(\"ymax\")))\n",
        "        if x2 > x1 and y2 > y1:\n",
        "            objs.append((name, x1, y1, x2, y2))\n",
        "    return objs\n",
        "\n",
        "label_set = set()\n",
        "for k in matched:\n",
        "    for name, *_ in parse_voc(xml_map[k]):\n",
        "        label_set.add(name)\n",
        "\n",
        "classes = sorted(label_set)\n",
        "print(\"Num classes:\", len(classes))\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(matched)\n",
        "\n",
        "n = len(matched)\n",
        "n_train = int(0.8 * n)\n",
        "n_val = int(0.1 * n)\n",
        "\n",
        "train_keys = matched[:n_train]\n",
        "val_keys = matched[n_train:n_train+n_val]\n",
        "test_keys = matched[n_train+n_val:]\n",
        "\n",
        "print(\"Split sizes:\", len(train_keys), len(val_keys), len(test_keys))\n",
        "\n",
        "def write_keys(keys, path):\n",
        "    with open(path, \"w\") as f:\n",
        "        for k in keys:\n",
        "            f.write(k + \"\\n\")\n",
        "\n",
        "write_keys(train_keys, os.path.join(OUT_KEYS, \"train.txt\"))\n",
        "write_keys(val_keys, os.path.join(OUT_KEYS, \"val.txt\"))\n",
        "write_keys(test_keys, os.path.join(OUT_KEYS, \"test.txt\"))\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for c in classes:\n",
        "        os.makedirs(os.path.join(LOCAL_CROPS, split, c), exist_ok=True)\n",
        "\n",
        "def safe_crop(img, x1, y1, x2, y2):\n",
        "    w, h = img.size\n",
        "    x1 = max(0, min(int(x1), w-1))\n",
        "    y1 = max(0, min(int(y1), h-1))\n",
        "    x2 = max(0, min(int(x2), w))\n",
        "    y2 = max(0, min(int(y2), h))\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        x2 = min(w, x1 + 1)\n",
        "        y2 = min(h, y1 + 1)\n",
        "    return img.crop((x1, y1, x2, y2))\n",
        "\n",
        "def make_crops(keys, split_name):\n",
        "    count = 0\n",
        "    for k in keys:\n",
        "        img = Image.open(img_map[k]).convert(\"RGB\")\n",
        "        for j, (name, x1, y1, x2, y2) in enumerate(parse_voc(xml_map[k])):\n",
        "            crop = safe_crop(img, x1, y1, x2, y2)\n",
        "            out_path = os.path.join(LOCAL_CROPS, split_name, name, f\"{k}__{j}.jpg\")\n",
        "            crop.save(out_path, quality=90)\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "c1 = make_crops(train_keys, \"train\")\n",
        "c2 = make_crops(val_keys, \"val\")\n",
        "c3 = make_crops(test_keys, \"test\")\n",
        "print(\"Crops counts:\", c1, c2, c3, \"| total:\", c1+c2+c3)\n",
        "\n",
        "with open(META_PATH, \"w\") as f:\n",
        "    f.write(\"classes=\" + \",\".join(classes) + \"\\n\")\n",
        "    f.write(\"num_classes=\" + str(len(classes)) + \"\\n\")\n",
        "    f.write(\"matched_pairs=\" + str(len(matched)) + \"\\n\")\n",
        "\n",
        "print(\"Meta saved:\", META_PATH)\n",
        "\n",
        "# Copy local crops -> Drive in one go (FASTER than writing directly to Drive)\n",
        "if os.path.exists(DRIVE_CROPS):\n",
        "    shutil.rmtree(DRIVE_CROPS)\n",
        "shutil.copytree(LOCAL_CROPS, DRIVE_CROPS)\n",
        "\n",
        "print(\"‚úÖ Crops copied to Drive:\", DRIVE_CROPS)\n",
        "print(\"‚úÖ Keys:\", OUT_KEYS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def remove_empty_class_dirs(root_dir):\n",
        "    removed = []\n",
        "    for cls in sorted(os.listdir(root_dir)):\n",
        "        cls_dir = os.path.join(root_dir, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        files = [f for f in os.listdir(cls_dir)\n",
        "                 if f.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))]\n",
        "        if len(files) == 0:\n",
        "            os.rmdir(cls_dir)\n",
        "            removed.append(cls)\n",
        "    return removed\n",
        "\n",
        "val_removed  = remove_empty_class_dirs(VAL_DIR)\n",
        "test_removed = remove_empty_class_dirs(TEST_DIR)\n",
        "\n",
        "print(\"Removed empty classes in val :\", val_removed)\n",
        "print(\"Removed empty classes in test:\", test_removed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXTV9TIsC8sA",
        "outputId": "77d4fc1f-f401-4103-f43a-03713a243130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed empty classes in val : []\n",
            "Removed empty classes in test: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/Final_product\"\n",
        "CROPS_DIR = os.path.join(ROOT, \"DataSet\", \"cls_crops\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(CROPS_DIR, \"train\")\n",
        "VAL_DIR   = os.path.join(CROPS_DIR, \"val\")\n",
        "TEST_DIR  = os.path.join(CROPS_DIR, \"test\")\n",
        "\n",
        "assert os.path.isdir(TRAIN_DIR), f\"Missing {TRAIN_DIR}\"\n",
        "assert os.path.isdir(VAL_DIR), f\"Missing {VAL_DIR}\"\n",
        "assert os.path.isdir(TEST_DIR), f\"Missing {TEST_DIR}\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "use_cuda = (device.type == \"cuda\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "train_tf = T.Compose([\n",
        "    T.Resize((256,256)),\n",
        "    T.RandomResizedCrop(224, scale=(0.75, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomApply([T.ColorJitter(0.2,0.2,0.15,0.02)], p=0.7),\n",
        "    T.RandomGrayscale(p=0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "eval_tf = T.Compose([\n",
        "    T.Resize((224,224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tf)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR,   transform=eval_tf)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR,  transform=eval_tf)\n",
        "\n",
        "classes = train_ds.classes\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(\"Num classes:\", num_classes)\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "BATCH = 64 if use_cuda else 32\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=use_cuda)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=use_cuda)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=use_cuda)\n",
        "\n",
        "print(\"train/val/test crops:\", len(train_ds), len(val_ds), len(test_ds))\n"
      ],
      "metadata": {
        "id": "vkyWKhlN4x8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5f4e8a-5888-4589-e608-a8d5b249cfb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "Num classes: 20\n",
            "Classes: ['A1', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A2', 'A20', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9']\n",
            "train/val/test crops: 6220 876 774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def remove_empty_class_dirs(root_dir):\n",
        "    removed = []\n",
        "    for cls in sorted(os.listdir(root_dir)):\n",
        "        cls_dir = os.path.join(root_dir, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        files = [f for f in os.listdir(cls_dir)\n",
        "                 if f.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))]\n",
        "        if len(files) == 0:\n",
        "            os.rmdir(cls_dir)\n",
        "            removed.append(cls)\n",
        "    return removed\n",
        "\n",
        "val_removed  = remove_empty_class_dirs(VAL_DIR)\n",
        "test_removed = remove_empty_class_dirs(TEST_DIR)\n",
        "\n",
        "print(\"Removed empty classes in val :\", val_removed)\n",
        "print(\"Removed empty classes in test:\", test_removed)\n"
      ],
      "metadata": {
        "id": "F7fPs9p5DbzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/Final_product\"\n",
        "CROPS_DIR = os.path.join(ROOT, \"DataSet\", \"cls_crops\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(CROPS_DIR, \"train\")\n",
        "VAL_DIR   = os.path.join(CROPS_DIR, \"val\")\n",
        "TEST_DIR  = os.path.join(CROPS_DIR, \"test\")\n",
        "\n",
        "assert os.path.isdir(TRAIN_DIR)\n",
        "assert os.path.isdir(VAL_DIR)\n",
        "assert os.path.isdir(TEST_DIR)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "use_cuda = device.type == \"cuda\"\n",
        "print(\"device:\", device)\n"
      ],
      "metadata": {
        "id": "6RYRuxm_5EOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37368779-fa51-44b6-f459-aa70b0f2b1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_empty_class_dirs(root_dir):\n",
        "    removed = []\n",
        "    for cls in os.listdir(root_dir):\n",
        "        cls_dir = os.path.join(root_dir, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            continue\n",
        "        files = [f for f in os.listdir(cls_dir)\n",
        "                 if f.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"))]\n",
        "        if len(files) == 0:\n",
        "            os.rmdir(cls_dir)\n",
        "            removed.append(cls)\n",
        "    return removed\n",
        "\n",
        "print(\"Removed empty classes in val :\", remove_empty_class_dirs(VAL_DIR))\n",
        "print(\"Removed empty classes in test:\", remove_empty_class_dirs(TEST_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXGMcxTDxzi",
        "outputId": "ba0d24c1-2a63-4bae-ac41-769bb00f1051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed empty classes in val : []\n",
            "Removed empty classes in test: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = T.Compose([\n",
        "    T.Resize((256,256)),\n",
        "    T.RandomResizedCrop(224, scale=(0.75, 1.0)),\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.RandomApply([T.ColorJitter(0.2,0.2,0.15,0.02)], p=0.7),\n",
        "    T.RandomGrayscale(0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "eval_tf = T.Compose([\n",
        "    T.Resize((224,224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tf)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR,   transform=eval_tf)\n",
        "test_ds  = datasets.ImageFolder(TEST_DIR,  transform=eval_tf)\n",
        "\n",
        "classes = train_ds.classes\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(\"Num classes:\", num_classes)\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "BATCH = 64 if use_cuda else 32\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=use_cuda)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=use_cuda)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=use_cuda)\n",
        "\n",
        "print(\"Crops train/val/test:\", len(train_ds), len(val_ds), len(test_ds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MKxn_JhD0YI",
        "outputId": "dfd21d95-9e38-4bc7-89a9-470f0cc6589a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num classes: 20\n",
            "Classes: ['A1', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A2', 'A20', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9']\n",
            "Crops train/val/test: 6220 876 774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "clf = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "for p in clf.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "clf.fc = nn.Linear(clf.fc.in_features, num_classes)\n",
        "clf.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.10)\n",
        "optimizer = optim.AdamW(clf.fc.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "EPOCHS = 20\n",
        "FREEZE_EPOCHS = 2\n",
        "PATIENCE = 4\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = GradScaler(\"cuda\") if use_cuda else None\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_acc(loader):\n",
        "    clf.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        out = clf(x)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "best_val_acc = 0.0\n",
        "bad_epochs = 0\n",
        "\n",
        "print(\"\\nüöÄ CLASSIFIER TRAINING START\\n\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "    if epoch == FREEZE_EPOCHS + 1:\n",
        "        for p in clf.parameters():\n",
        "            p.requires_grad = True\n",
        "        optimizer = optim.AdamW(clf.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - epoch + 1)\n",
        "        print(\"üîì backbone unfrozen\")\n",
        "\n",
        "    clf.train()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        if scaler:\n",
        "            with autocast(\"cuda\"):\n",
        "                out = clf(x)\n",
        "                loss = criterion(out, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            out = clf(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    val_acc = eval_acc(val_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        bad_epochs = 0\n",
        "        torch.save({\n",
        "            \"model_state_dict\": clf.state_dict(),\n",
        "            \"classes\": classes,\n",
        "            \"class_to_idx\": class_to_idx\n",
        "        }, os.path.join(ROOT, \"models\", \"best_crop_classifier_resnet50.pth\"))\n",
        "        print(\"‚úÖ saved best\")\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "\n",
        "    if bad_epochs >= PATIENCE:\n",
        "        print(\"‚èπ early stopping\")\n",
        "        break\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t06K-puFD2r0",
        "outputId": "6291c6bb-c448-4f1e-fdc5-ad259068e623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ CLASSIFIER TRAINING START\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "MODEL_PATH = os.path.join(ROOT, \"models\", \"best_crop_classifier_resnet50.pth\")\n",
        "ckpt = torch.load(MODEL_PATH, map_location=device)\n",
        "\n",
        "model = models.resnet50(weights=None)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(ckpt[\"classes\"]))\n",
        "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_acc(loader):\n",
        "    correct, total = 0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        out = model(x)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "acc = test_acc(test_loader)\n",
        "print(\"‚úÖ Test accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "fGhy6CAxD68b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}